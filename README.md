# CS795_Company_Sentiment

## graphql-sa-frontend/
   contains a development server for React UI development

## graphql-sa-server/
   contains an apollo-graphql server which will serve the data to clients

## Analysis
    contains all code for sentiment analysis

## To run:
1) In ```./Analysis```:
    a) ```docker build -t masters/sentanalysis:latest .```
    b) ```docker run -p 5000:5000 masters/sentanalysis:latest```
2) In ```./graphql-sa-frontend```:
    a) ```npm i```
    b) ```npm start```
3) In ```./graphql-sa-server```:
    a) ```npm i```
    b) ```npm start```

Sentiment Analysis on Twitter Data for Companies
Sean Workman
Department of Computer Science
Old Dominion University
Norfolk, VA 23529
swork002@odu.edu

Abstract
With the increasing amount of tweets and other social media data in today’s world it is easy to see opinions about virtually every subject from every walk of life. While the opinions of everyone are out there it is hard to sift through the endless amount of data on these social media platforms. That is why I have proposed a solution that will allow the everyday person to  search for a company and quickly see the opinion of the public as a whole by gathering Twitter data and determining a general sentiment.
1 Introduction
In today’s world social media drives so many different things, from social justice to stocks. We really saw the power of social media on stocks this year, GameStop Corp’s stock increased 2,400% in just 2 months all because some people on Reddit wanted it to. While GameStop took most of the spotlight there were countless other companies that sky rocketed out of nowhere, helping some stay alive and pivot their business models. This isn’t a new phenomenon, back in 2018 a simple tweet from Kylie Jenner was a factor in Snap Inc. dropping 7% in one day. While this is an interesting problem to tackle there is a similar problem that exists in regards to the relationship of companies and social media. For the normal person, that isn’t a savvy stock trader, their view of a company is based on the few and far between news articles about something bad a company did. When in reality people are talking about companies and products all the time on social media. This chatter is almost always lost in the overwhelming amount of other posts on social media. Companies also rely on customer reviews of products and surveys to guide other customers to the right product, the problem with that is there are a select group of people that take the time to review a product on the company website. This means the company and the consumer are missing out on valuable data that is being posted on social media about their products. A company would be able to adjust before something catastrophic happens with the company as a whole or an individual product if they had live data on what people were saying on social media. Giving a company the ability to watch a trend of social media posts would tell them what the world is truly thinking. This wouldn’t only help large companies get ahead of problems or better determine what they are doing right, it would also help the consumer to make more informed purchases based on product sentiment and company sentiment from social media.
A solution to this problem is to create a site where anyone can enter a company name or product into and see the overall sentiment analysis of that product or company based on social media posts. Once a company or product is entered a scraper will be sent out to gather as much recent social media data as possible then each post will be run through a sentiment analysis to get an aggregate sentiment and determine the overall view of the company or product, as well as provide a selection of posts that helped drive that sentiment analysis. The analysis can be tweaked to more heavily weight posts by more popular accounts or in later iterations posts by more consistent accounts. Historical data can also be stored to create trend lines for companies or products. Other than the main search view other views like popular companies (i.e. Walmart, Amazon, Google, etc…), biggest sentiment fluctuations, and most talked about can be incorporated. For the popular companies view an automated scraper can be sent out in certain intervals to gather and analyze those posts. The biggest sentiment fluctuations view can be created from analyzing historical data from popular companies and past searches. The most talked about view would simply take a list of publicly traded companies, and possibly large private companies like Walmart, and rank them based on how many posts included them, no sentiment analysis needed. If the user wants more detail on a most talked about company they could simply click it and get the sentiment analysis for it. In the first iteration this solution would only apply to Twitter, in later iterations it will branch out to Facebook, Instagram, and Reddit. 
I chose this topic because over the past few years I have begun to notice the major impacts social media can have on the real world. After the elections any social media user saw an obvious divide in the country on views and support, this was just an observation that I never acted on because I assumed it was a niche group of wildcards posting. However, the biggest driver was this year’s stock market chaos. Seeing how much a simple social media group can effect a global entity like the New York Stock Exchange was shocking. After that I realized how little people paid attention to the power of social media and the amount of data that can be gathered from it. This lead me to the solution I stated above, in the beginning it was based around stock trading advice for novice traders but recently I have realized that it would also be beneficial to the companies themselves and their consumers. Sentiment analysis has always been an interest of mine, the concept of “understanding” what a person is saying without a person even reading what they wrote is incredibly powerful. I soon realized that the large amount of small individual statements or posts would be a great application for sentiment analysis and the aggregation of sentiment analysis. Another thing that interested me was finding a way to map the social media way of speaking to understandable English, this interest rose from a project I am working on for work that involves mapping military chat data to English and vice versa. I never thought about the impacts different text syntax would have to AI models but once I did I was immediately interested. Of course military syntax is much more standardized than social media but that just opens the door to more interesting solutions. The variance in spellings of words to get around filters (i.e. “fuck” can be spelled “phuck”) is also a tricky problem to solve, while it won’t be the main focus of this project it would be something interesting to look at, trying to capture the pronunciation of a word and map it back to a real word doesn’t seem to have a readily available solution. A part of getting to the solution is determining the ground truth for the sentiment, aligning major fluctuations in sentiment from social media to major news stories or stock fluctuations is an interesting problem to solve in its own.
2 Related Work
From my readings of papers on sentiment analysis of twitter data the main difference between them seems to be the pre-processing techniques of the data (tweets) [Agarwal et al.[1];  Barbosa; Feng[2]; Kharde, Sonawane[4];  Alsaeedi, Khan[5]; Reddy, Subhash[8]]. There were some differences in the models being used, and the classification goals were either two way (positive-negative) [Agarwal et al.[1]; Barbosa, Feng[2]; Spencer, Uchyigit[3];  Kharde, Sonawane[4];  Bharti, Malhotra[7]] or three way (positive-negative-neutral) [Agarwal et al.[1];  Barbosa; Feng[2];  Sharma, Ghose[6]; Rasool et al.[9]; Weber, Syed[10]; Khattak et al.[11]; Munson[12]; Sahayak, Shete, Pathan[13];  Fang, Zhan[14]] classification. 
2.1 Sentiment Analysis
The types of models used by Agarwal et al. [1]  were a unigram model, a feature based model, and a tree kernel based model. The unigram model was used as the baseline which achieved 20% over chance baseline, I will also be using a unigram model as a baseline. Barbosa; Feng[2] used a 2 step sentiment analysis classification method which includes classifying messages as subjective and objective firstly, followed by distinguishing the subjective tweets as positive or negative. This is an interesting idea to narrow the focus of the analysis and I will probably employ this strategy as well. Along with the unigram model I plan to use a bigram and pre-trained models from various python libraries, such as NLTK. 
2.2 Pre-processing
For pre-processing Agarwal et al.[1] replaced all emoticons with their sentiment polarity (i.e. “=)” is positive), replaced URLs and mentions (i.e. “@John”) with tags, replaced all negations by the tag “NOT”, and replaced a sequence of repeated characters by three characters (i.e. “coooool” to “coool”) this retains the emphasized use of the word. Barbosa; Feng[2] did similar pre-processing. I will also be using these techniques but add a few more; while both mapped “old school” emoticons I hope to also map “new school” emojis as well, there was no mention of tweets including images so I hope to incorporate those by generating a description of the image and adding that to the tweet’s text, and lastly I hope to solve the problem of phonetic and different spellings of words (i.e. “ph”=”f”, “@”=a, “0”=”o”, etc…) by mapping them to standard English text. Along with the pre-processing used in the papers these added techniques should increase the amount of data a sentiment analysis will look at. Another aspect was the method in which they mapped words to their polarity. Agarwal et al.[1] seemed to have the more robust mapping of words to polarity; this method involved using the Dictionary of Affect in Language (DAL) extended by using WordNet. For the words that are not directly found in the DAL synonyms are retrieved from WordNet, the synonyms are then searched for in the DAL and if found their polarity is attributed to the original word. This method accounted for ~88.9% of English language words. Barbosa; Feng[2] added a features for “tweet syntax” which includes retweet, hashtag, reply, if the tweet contains a link, punctuation (exclamation and question marks), emoticons, and upper cases. The frequency of each feature in a tweet is divided by the number of the words in the tweet. I would also like to include these tweet syntax features but expand on it, to add a sort of weighted feature. Tweets from accounts with more followers will have a larger impact than other tweets, also a tweet with a higher number of likes, retweets, and shares will have a larger impact.
3 Architecture
3.1 Diagram 
3.2 Overview
The application will be a micro-service oriented web-application with a ReactJS frontend, NodeJS server, a graph database for storage, and python micro-services for data preprocessing, sentiment analysis, and sentiment aggregation.
3.2.1 Company Search
The company search component of the application will be hosted on a web page developed with ReactJS, a JavaScript framework. In early iterations this component won’t include much other than a search area and a display area for results.
3.2.2 Tweet Retrieval 
The next component of the application will be tweet retrieval. The company that was entered into the search area will be passed to a python micro-service containing a connection to a Twitter API endpoint. The Twitter API will be used to gather and retrieve tweets using a search criteria that includes the initial company name searched, the ticker symbol obtained from a finance python library, the company’s twitter handle, and any abbreviations the company may use. The number of tweets retrieved will be based on availability in a designated time frame.
3.2.3 Data Preprocessing 
The data preprocessing will also be a python micro-service that is triggered when a certain threshold of tweets are gathered from the tweet retrieval service. In this service each tweet will be processed to normalize emoticons (“”, “”, etc…) and emojis, normalize any phonetic and different spellings of words (i.e. “ph”=”f”, “@”=a, “0”=”o”, etc…), remove any mentions or links imbedded in the tweet, normalize common “internet” language (i.e. “to the moon” is a positive statement), and a stretch goal to generate descriptions of images. This will help to add more usable data in the sentiment analysis.
3.2.4 Sentiment Analysis & Sentiment Aggregation
This component will serve as the backbone of the entire application. Like the other components this will be a python micro-service. In this service the processed data from the previous service will be fed into this service for sentiment analysis and aggregation. The models being used will be n-grams and pre-trained models from python libraries such as NLTK. The various models will be tested for accuracy by using a unigram as a baseline and datasets of pre-tagged twitter data. This pre-tagged data will come from NLTK and data.world datasets. The NLTK datasets are typical tweet data but the data.world dataset will be tweets focused on companies including Apple. Pre-tagged datasets are being used because of limitations of the Twitter API, specifically the limitation of the number of tweets that can be gathered over certain periods of time. For the n-grams polarity will be determined by methods used by Agarwal et al.[1]. Additional features will be used to add weights to tweets including; number of likes and retweets, and popularity of the user that posted the tweet. Sentiment will be classified in 3 categories; positive, neutral, and negative. An aggregation of the sentiment will be performed to determine an “overall sentiment”. The aggregation method is yet to be determined; initially a simple average seems like the best method but further research will be done to determine that.
3.2.5 Data Storage
Data will be stored in a graph database for easier retrieval in displaying of results. A graph will also allow that data to be more easily expanded for later iterations. The data being stored will include, but is not limited to: previously searched companies with their aggregate sentiment and a certain number of tweets from each search with their individual sentiment. These can also be used in later iterations to track historical data for trend lines and speed up recent searches of the same companies.
3.2.6 Display Results
The results will be displayed on the same page as the search component. The initial data that will be displayed will be the overall sentiment of the company and a selection of tweets to show examples of what led to that result.
3.3. Rational for Chosen Architecture 
There were a couple of design decisions made for this application; web-based, micro-service, and graph database. A web-based solution is being used because that is where my experience lies and I feel it is the most versatile, easily expandable, and easily accusable solution, especially when utilizing frameworks like ReactJS. A micro-service architecture was chosen because it allows for services to be utilized in any portion of the application and in other applications. The modular nature of a micro-service architecture also allows for easier debugging and development. Lastly, a graph database was chosen for its data retrieval capabilities, ability to model data in a semantic manor, and its expandability. All of these decisions were made with expandability and modularity in mind. 
4 Conclusion
In researching and experimenting with various models; unigram, bigram, and NLTK pre-trained models I found that the unigram gave the most accurate results. This may be due to various different things that are discussed in the next section. Due to time constraints some preprocessing techniques were not able to be included as well as a more complex method of discerning sentiment of individual words such as using the DLA and WordNet. While this is a working solution the continued work may lead to much more accurate and consistent results. 
5 Continued Work
Preprocessing of tweet data can be expanded to include generation of descriptions of images imbedded in tweets, normalization of a larger set of emojis, and better normalization of misspelled words. Because of the limitations of the Twitter API being used adding features such as number of likes and retweets and popularity of the account that made the tweet could not be included in this work. My hope is to explore more API options and include these features later. To place more focus on the sentiment analysis and data processing the data storage feature of this architecture was left out. This feature will allow for trends to be analyzed in the future. Different methods of sentiment aggregation will also be explored, the current method is an average of “hard” polarities (i.e. -1 for negative, 0 for neutral, and 1 for positive). Results may become more accurate if the actual float representation of the polarity was taken into account. 

 
References
 
1.	Agarwal et al. Sentiment Analysis of Twitter Data (aclanthology.org)
2.	Barbosa, Feng  Robust Sentiment Detection on Twitter from Biased and Noisy Data (aclanthology.org)
3.	Spencer, Uchyigit SDAD2012-with-cover-page-v2.pdf (d1wqtxts1xzle7.cloudfront.net)
4.	Kharde, Sonawane Sentiment Analysis of Twitter Data: A Survey of Techniq (arxiv.org)
5.	Alsaeedi, Khan A Study on Sentiment Analysis Techniques of Twitter Data (thesai.org)
6.	Sharma, Ghose Elsevier Enhanced Reader
7.	Bharti, Malhotra V5I6201690.pdf (ijcsmc.com)
8.	Reddy, Subhash B11810982S1119.pdf (ijrte.org)
9.	Rasool et al. https://iopscience.iop.org/article/10.1088/1742-6596/1176/2/022015/pdf
10.	Weber, Syed Interdisciplinary optimism? Sentiment analysis of Twitter data | Royal Society Open Science (royalsocietypublishing.org)
11.	Khattak et al. Tweets Classification and Sentiment Analysis for Personalized Tweets Recommendation (hindawi.com)
12.	Munson Sentiment Analysis of Twitter Data (afit.edu)
13.	Sahayak, Shete, Pathan Microsoft Word - 28.JACS10092 (ijirae.com)
14.	Fang, Zhan Sentiment analysis using product review data | Journal of Big Data | Full Text (springeropen.com)
 



